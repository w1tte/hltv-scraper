---
phase: 02-storage-foundation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/scraper/config.py
  - src/scraper/db.py
  - src/scraper/storage.py
  - migrations/001_initial_schema.sql
  - .gitignore
autonomous: true

must_haves:
  truths:
    - "SQLite database is created at data/hltv.db with WAL mode, foreign keys ON, and busy_timeout set"
    - "Running migrations applies 001_initial_schema.sql and sets PRAGMA user_version to 1"
    - "All 5 tables exist: matches, maps, player_stats, round_history, economy with correct columns and constraints"
    - "Raw HTML can be saved as gzip-compressed files and loaded back identically"
    - "HTML files are organized under data/raw/matches/{match_id}/ by page type"
  artifacts:
    - path: "migrations/001_initial_schema.sql"
      provides: "Initial database schema DDL"
      contains: "CREATE TABLE IF NOT EXISTS matches"
    - path: "src/scraper/db.py"
      provides: "Database connection manager with migration support"
      exports: ["Database"]
    - path: "src/scraper/storage.py"
      provides: "Gzipped HTML save/load/exists filesystem layer"
      exports: ["HtmlStorage"]
    - path: "src/scraper/config.py"
      provides: "Updated config with data_dir and db_path"
      contains: "data_dir"
  key_links:
    - from: "src/scraper/db.py"
      to: "migrations/001_initial_schema.sql"
      via: "apply_migrations reads and executes SQL files"
      pattern: "glob.*\\.sql"
    - from: "src/scraper/db.py"
      to: "src/scraper/config.py"
      via: "Database uses db_path from config or constructor"
      pattern: "db_path"
    - from: "src/scraper/storage.py"
      to: "data/raw/matches/"
      via: "HtmlStorage builds paths under base_dir/matches/{match_id}/"
      pattern: "matches.*match_id"
---

<objective>
Create the database schema, database connection manager, and raw HTML storage layer -- the two foundational storage systems that all downstream phases depend on.

Purpose: Every subsequent phase (3-9) needs either the database (to persist structured data) or the HTML storage (to archive raw pages). This plan establishes both foundations.
Output: migrations/001_initial_schema.sql, src/scraper/db.py, src/scraper/storage.py, updated config.py, .gitignore
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-storage-foundation/02-CONTEXT.md
@.planning/phases/02-storage-foundation/02-RESEARCH.md
@src/scraper/config.py
@src/scraper/__init__.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Database schema migration and connection manager</name>
  <files>
    migrations/001_initial_schema.sql
    src/scraper/db.py
    src/scraper/config.py
    .gitignore
  </files>
  <action>
Create the initial database schema and the Python class that manages the SQLite connection lifecycle.

**migrations/001_initial_schema.sql:**
Create all 5 tables with the exact schema from the research document (Section "Complete Database Schema (Migration 001)"):
- `matches` table: match_id INTEGER PRIMARY KEY, date, event_id, event_name, team1_id, team1_name, team2_id, team2_name, team1_score, team2_score, best_of, is_lan, match_url, scraped_at, updated_at, source_url, parser_version
- `maps` table: PRIMARY KEY (match_id, map_number), mapstatsid, map_name, round scores (total, CT, T for each team), provenance columns, FOREIGN KEY to matches
- `player_stats` table: PRIMARY KEY (match_id, map_number, player_id), all stat columns (kills through rating_3, kpr, dpr, impact), provenance, FOREIGN KEY to maps (composite)
- `round_history` table: PRIMARY KEY (match_id, map_number, round_number), winner_side, win_type, winner_team_id, provenance, FOREIGN KEY to maps
- `economy` table: PRIMARY KEY (match_id, map_number, round_number, team_id), equipment_value, buy_type, provenance, FOREIGN KEY to round_history (composite: match_id, map_number, round_number)
- All 6 indexes from the research: idx_matches_date, idx_matches_event, idx_matches_teams, idx_maps_mapstatsid, idx_player_stats_player, idx_player_stats_team
- Use `CREATE TABLE IF NOT EXISTS` and `CREATE INDEX IF NOT EXISTS` for idempotency
- Do NOT put `PRAGMA user_version` in the SQL file -- the migration runner sets it

**src/scraper/db.py:**
Create a `Database` class following the research Pattern 1 (Database Connection Manager) and Pattern 3 (Migration via PRAGMA user_version):
- `__init__(self, db_path: str | Path)` -- stores path, ensures parent directory exists
- `connect(self) -> sqlite3.Connection` -- opens connection, sets row_factory=sqlite3.Row, executes PRAGMA journal_mode=WAL, PRAGMA foreign_keys=ON, PRAGMA busy_timeout=5000
- `conn` property -- returns connection or raises RuntimeError if not connected
- `close(self)` -- closes connection, sets _conn to None
- `__enter__` / `__exit__` -- context manager for connect/close lifecycle
- `get_schema_version(self) -> int` -- returns PRAGMA user_version
- `apply_migrations(self, migrations_dir: Path | None = None) -> int` -- applies pending SQL files from migrations/ directory. Default migrations_dir should be `Path(__file__).resolve().parent.parent.parent / "migrations"` (project root / migrations). Sorts files by name, extracts version from `NNN_` prefix, skips versions <= current user_version, executes with `executescript()`, sets `PRAGMA user_version = {version}` after each. Returns count applied.
- `initialize(self) -> sqlite3.Connection` -- convenience method that calls connect() then apply_migrations(), returns conn. This is the standard entry point.

**src/scraper/config.py:**
Add two new fields to ScraperConfig:
- `data_dir: str = "data"` -- base directory for all persistent data
- `db_path: str = "data/hltv.db"` -- SQLite database file path

**.gitignore:**
Create a project-root .gitignore with:
```
data/
*.egg-info/
__pycache__/
*.pyc
.pytest_cache/
```
  </action>
  <verify>
Run: `python -c "from scraper.db import Database; db = Database('data/hltv.db'); db.initialize(); v = db.get_schema_version(); print(f'Schema version: {v}'); assert v == 1; db.close(); print('OK')"` from the src/ directory (or use PYTHONPATH).

Also verify: `python -c "import sqlite3; conn = sqlite3.connect('data/hltv.db'); tables = [r[0] for r in conn.execute(\"SELECT name FROM sqlite_master WHERE type='table'\").fetchall()]; print(tables); assert set(tables) >= {'matches', 'maps', 'player_stats', 'round_history', 'economy'}; conn.close(); print('OK')"`
  </verify>
  <done>
Database file data/hltv.db exists with schema version 1. All 5 tables and 6 indexes are created. WAL mode is active. Foreign keys are enforced. Config has data_dir and db_path fields. .gitignore excludes data/ directory.
  </done>
</task>

<task type="auto">
  <name>Task 2: Raw HTML filesystem storage layer</name>
  <files>
    src/scraper/storage.py
  </files>
  <action>
Create `HtmlStorage` class following the research Pattern 4 (Raw HTML Storage Layer):

- Class with `PAGE_TYPES` dict mapping page type strings to filename templates:
  - `"overview"` -> `"overview.html.gz"`
  - `"map_stats"` -> `"map-{mapstatsid}-stats.html.gz"`
  - `"map_performance"` -> `"map-{mapstatsid}-performance.html.gz"`
  - `"map_economy"` -> `"map-{mapstatsid}-economy.html.gz"`
  - `"results"` -> `"results.html.gz"` (for Phase 4 results listing pages -- store under match_id=0 or a dedicated results/ subdirectory; use a `results/{offset}` path pattern instead of match-centric: `self.base_dir / "results" / f"offset-{offset}.html.gz"`)

Actually, keep results storage simple: the `save` and `load` methods are match-centric (match_id + page_type + optional mapstatsid). Results listing pages are a different concern and will be handled in Phase 4. Do NOT add results page support now -- only the 4 match-page types listed in the research.

- `__init__(self, base_dir: str | Path)` -- stores Path(base_dir)
- `save(self, html: str, match_id: int, page_type: str, mapstatsid: int | None = None) -> Path` -- builds file path, creates parent dirs, gzip-compresses the HTML string (encode utf-8 first, then gzip.compress), writes bytes, returns the Path
- `load(self, match_id: int, page_type: str, mapstatsid: int | None = None) -> str` -- reads bytes, gzip.decompress, decode utf-8, returns string
- `exists(self, match_id: int, page_type: str, mapstatsid: int | None = None) -> bool` -- returns whether the file exists
- `list_match_files(self, match_id: int) -> list[Path]` -- returns all .html.gz files in the match directory (useful for knowing what has been fetched)
- `_build_path(self, match_id: int, page_type: str, mapstatsid: int | None) -> Path` -- builds `self.base_dir / "matches" / str(match_id) / filename`. Raises ValueError if page_type not in PAGE_TYPES. Raises ValueError if page_type requires mapstatsid but it is None.

Key implementation details:
- Use `gzip.compress(html.encode("utf-8"))` for save (NOT gzip.open -- we want the bytes for write_bytes)
- Use `gzip.decompress(file_path.read_bytes()).decode("utf-8")` for load
- Raise FileNotFoundError with a descriptive message if load() is called for a file that does not exist
- All path operations via pathlib.Path
  </action>
  <verify>
Run: `python -c "
from scraper.storage import HtmlStorage
from pathlib import Path
import tempfile, os

with tempfile.TemporaryDirectory() as tmp:
    s = HtmlStorage(tmp)
    # Save and load overview
    p = s.save('<html>test</html>', 12345, 'overview')
    assert p.exists()
    assert p.suffix == '.gz'
    html = s.load(12345, 'overview')
    assert html == '<html>test</html>'
    # Save and load map stats
    p2 = s.save('<html>map</html>', 12345, 'map_stats', mapstatsid=67890)
    assert 'map-67890-stats' in p2.name
    assert s.exists(12345, 'map_stats', 67890)
    assert not s.exists(12345, 'map_economy', 67890)
    # List files
    files = s.list_match_files(12345)
    assert len(files) == 2
    print('All checks passed')
"` from src/ directory.
  </verify>
  <done>
HtmlStorage class saves gzip-compressed HTML files under data/raw/matches/{match_id}/ organized by page type. Round-trip save/load preserves HTML content exactly. Exists check works. File listing works. ValueError raised for invalid page types or missing mapstatsid.
  </done>
</task>

<task type="auto">
  <name>Task 3: Unit tests for database and storage</name>
  <files>
    tests/test_db.py
    tests/test_storage.py
  </files>
  <action>
Create comprehensive unit tests for both the Database class and HtmlStorage class. Use tmp_path fixture (pytest built-in) for all tests to avoid touching real data/ directory. Follow existing test conventions from Phase 1 (pytest-asyncio strict mode, though these tests are all synchronous).

**tests/test_db.py:**
- `test_database_creates_file` -- Database(tmp_path/"test.db").initialize() creates the .db file on disk
- `test_database_schema_version` -- After initialize(), get_schema_version() returns 1
- `test_database_wal_mode` -- After connect, PRAGMA journal_mode returns "wal"
- `test_database_foreign_keys_enabled` -- After connect, PRAGMA foreign_keys returns 1
- `test_database_all_tables_created` -- After initialize(), SELECT name FROM sqlite_master lists all 5 tables
- `test_database_all_indexes_created` -- After initialize(), SELECT name FROM sqlite_master WHERE type='index' lists all 6 custom indexes (plus any auto-created for PKs)
- `test_database_context_manager` -- `with Database(path) as db:` connects and closes properly
- `test_database_connect_without_initialize` -- connect() without apply_migrations() gives schema version 0, no tables
- `test_database_migration_idempotent` -- Running apply_migrations() twice returns 0 on second call (already applied)
- `test_database_foreign_key_enforcement` -- Insert a player_stats row referencing a non-existent match_id -> raises sqlite3.IntegrityError
- `test_database_conn_property_raises_without_connect` -- Accessing .conn before connect() raises RuntimeError

**tests/test_storage.py:**
- `test_save_and_load_overview` -- Save overview HTML, load it back, assert identical
- `test_save_and_load_map_stats` -- Save map_stats with mapstatsid, load back, assert identical
- `test_save_and_load_map_performance` -- Same for map_performance
- `test_save_and_load_map_economy` -- Same for map_economy
- `test_exists_true` -- After save, exists() returns True
- `test_exists_false` -- Before save, exists() returns False
- `test_load_nonexistent_raises` -- load() for missing file raises FileNotFoundError
- `test_invalid_page_type_raises` -- save() with page_type="invalid" raises ValueError
- `test_map_type_without_mapstatsid_raises` -- save() with page_type="map_stats" and mapstatsid=None raises ValueError
- `test_list_match_files_empty` -- list_match_files for non-existent match returns empty list
- `test_list_match_files_multiple` -- Save 3 files for same match, list returns 3 paths
- `test_file_is_gzip_compressed` -- Save HTML, read raw bytes, verify they start with gzip magic bytes (0x1f, 0x8b)
- `test_unicode_roundtrip` -- Save HTML with unicode characters (accents, CJK), load back, assert identical
- `test_large_html_roundtrip` -- Save ~200KB of HTML (realistic HLTV page size), load back, assert identical
- `test_directory_structure` -- Save overview for match 12345, verify path is base_dir/matches/12345/overview.html.gz

All tests use `tmp_path` fixture. No network access. No real data/ directory.
  </action>
  <verify>
Run: `python -m pytest tests/test_db.py tests/test_storage.py -v` from the project root. All tests must pass. Also run the full suite: `python -m pytest tests/ -m "not integration" -v` to confirm no regressions in Phase 1 tests.
  </verify>
  <done>
All database tests pass: schema creation, migration, WAL mode, foreign keys, context manager, idempotency, FK enforcement.
All storage tests pass: save/load round-trip for all 4 page types, exists checks, error handling, gzip verification, unicode, large HTML, directory structure.
Phase 1 tests still pass (no regressions).
  </done>
</task>

</tasks>

<verification>
1. `python -m pytest tests/test_db.py tests/test_storage.py -v` -- all tests pass
2. `python -m pytest tests/ -m "not integration" -v` -- full unit suite passes (Phase 1 + Phase 2 tests)
3. Database file at data/hltv.db has schema version 1 with all 5 tables and 6 indexes
4. HTML round-trip: save a string via HtmlStorage, load it back, strings are identical
5. Foreign key enforcement: inserting orphaned child rows raises IntegrityError
</verification>

<success_criteria>
- Database class creates and initializes SQLite DB with WAL, FK ON, busy_timeout
- Migration runner applies 001_initial_schema.sql and sets user_version to 1
- All 5 tables exist with correct columns, types, PKs, and FK constraints
- HtmlStorage saves gzip-compressed HTML and loads it back identically
- Files stored at data/raw/matches/{match_id}/{page_type}.html.gz
- All unit tests pass, no regressions in Phase 1 tests
</success_criteria>

<output>
After completion, create `.planning/phases/02-storage-foundation/02-01-SUMMARY.md`
</output>
