---
phase: 02-storage-foundation
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - src/scraper/repository.py
  - tests/test_repository.py
autonomous: true

must_haves:
  truths:
    - "Upserting a match row twice with different data keeps only one row with the latest values and updated_at timestamp"
    - "Upserting player_stats, round_history, and economy rows respects composite primary keys without duplicates"
    - "Inserting a child row (map, player_stats) for a non-existent parent (match, map) raises IntegrityError due to FK"
    - "Batch upsert of multiple rows for a match is atomic -- all succeed or all rollback"
  artifacts:
    - path: "src/scraper/repository.py"
      provides: "UPSERT operations for all 5 tables"
      exports: ["MatchRepository"]
      min_lines: 80
    - path: "tests/test_repository.py"
      provides: "Tests for all UPSERT operations and edge cases"
      min_lines: 100
  key_links:
    - from: "src/scraper/repository.py"
      to: "src/scraper/db.py"
      via: "MatchRepository takes a sqlite3.Connection (from Database.conn)"
      pattern: "sqlite3\\.Connection"
    - from: "src/scraper/repository.py"
      to: "migrations/001_initial_schema.sql"
      via: "UPSERT SQL references table/column names matching the schema"
      pattern: "ON CONFLICT.*DO UPDATE"
    - from: "tests/test_repository.py"
      to: "src/scraper/repository.py"
      via: "Tests import and exercise MatchRepository"
      pattern: "from scraper.repository import"
    - from: "tests/test_repository.py"
      to: "src/scraper/db.py"
      via: "Tests use Database to create in-memory or tmp_path databases"
      pattern: "from scraper.db import"
---

<objective>
Build the data access layer with UPSERT operations for all 5 database tables, enabling all downstream parsing phases to persist structured data without worrying about duplicates.

Purpose: Phases 4-9 need to write parsed data to the database. This plan provides the write API so parsers can call `repo.upsert_match(data)` instead of writing raw SQL.
Output: src/scraper/repository.py, tests/test_repository.py
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-storage-foundation/02-CONTEXT.md
@.planning/phases/02-storage-foundation/02-RESEARCH.md
@.planning/phases/02-storage-foundation/02-01-SUMMARY.md
@src/scraper/db.py
@migrations/001_initial_schema.sql
</context>

<tasks>

<task type="auto">
  <name>Task 1: Repository with UPSERT operations for all tables</name>
  <files>
    src/scraper/repository.py
  </files>
  <action>
Create a `MatchRepository` class that wraps all database write and read operations. The class receives a `sqlite3.Connection` in its constructor (not a Database instance -- keep it decoupled so tests can pass any connection).

**Class: MatchRepository**
- `__init__(self, conn: sqlite3.Connection)` -- stores the connection

**UPSERT methods (one per table):**
Each method takes a dict of column values, uses `INSERT ... ON CONFLICT DO UPDATE SET` with `:named` parameter placeholders. Use `with self.conn:` for automatic commit/rollback.

1. `upsert_match(self, data: dict) -> None`
   - INSERT into matches with all columns
   - ON CONFLICT(match_id) DO UPDATE SET all columns except match_id, set updated_at = excluded.scraped_at
   - Follow the exact UPSERT_MATCH SQL pattern from the research

2. `upsert_map(self, data: dict) -> None`
   - INSERT into maps with all columns
   - ON CONFLICT(match_id, map_number) DO UPDATE SET all non-PK columns
   - updated_at = excluded.scraped_at

3. `upsert_player_stats(self, data: dict) -> None`
   - INSERT into player_stats with all columns
   - ON CONFLICT(match_id, map_number, player_id) DO UPDATE SET all non-PK columns
   - updated_at = excluded.scraped_at
   - Follow the exact UPSERT_PLAYER_STATS SQL pattern from the research

4. `upsert_round(self, data: dict) -> None`
   - INSERT into round_history with all columns
   - ON CONFLICT(match_id, map_number, round_number) DO UPDATE SET all non-PK columns
   - updated_at = excluded.scraped_at

5. `upsert_economy(self, data: dict) -> None`
   - INSERT into economy with all columns
   - ON CONFLICT(match_id, map_number, round_number, team_id) DO UPDATE SET all non-PK columns
   - updated_at = excluded.scraped_at

**Batch methods for efficiency:**

6. `upsert_match_maps(self, match_data: dict, maps_data: list[dict]) -> None`
   - Atomic: upsert match + all maps in a single `with self.conn:` transaction
   - This is what Phase 5 will call after parsing an overview page

7. `upsert_map_player_stats(self, stats_data: list[dict]) -> None`
   - Atomic: upsert multiple player_stats rows in a single transaction
   - Use a loop inside `with self.conn:` (NOT executemany -- we need ON CONFLICT per row)

8. `upsert_map_rounds(self, rounds_data: list[dict]) -> None`
   - Atomic: upsert multiple round_history rows in a single transaction

9. `upsert_map_economy(self, economy_data: list[dict]) -> None`
   - Atomic: upsert multiple economy rows in a single transaction

**Read methods (simple, for verification and pipeline use):**

10. `get_match(self, match_id: int) -> dict | None`
    - SELECT * FROM matches WHERE match_id = ? -- returns dict(row) or None

11. `get_maps(self, match_id: int) -> list[dict]`
    - SELECT * FROM maps WHERE match_id = ? ORDER BY map_number

12. `get_player_stats(self, match_id: int, map_number: int) -> list[dict]`
    - SELECT * FROM player_stats WHERE match_id = ? AND map_number = ? ORDER BY player_id

13. `count_matches(self) -> int`
    - SELECT COUNT(*) FROM matches

**Implementation notes:**
- Store each UPSERT SQL as a module-level constant string (UPSERT_MATCH, UPSERT_MAP, etc.) for readability
- Use `:named` parameters (not `?` positional) for clarity since the dicts have named keys
- Every `with self.conn:` block handles commit on success, rollback on exception
- Do NOT catch exceptions -- let IntegrityError, OperationalError propagate to callers
- Read methods: convert sqlite3.Row to dict via `dict(row)` for easier consumption
  </action>
  <verify>
Run: `python -c "
from scraper.db import Database
from scraper.repository import MatchRepository
import tempfile
with tempfile.TemporaryDirectory() as tmp:
    db = Database(f'{tmp}/test.db')
    db.initialize()
    repo = MatchRepository(db.conn)
    repo.upsert_match({
        'match_id': 1, 'date': '2025-01-01', 'event_id': 10, 'event_name': 'Test',
        'team1_id': 100, 'team1_name': 'TeamA', 'team2_id': 200, 'team2_name': 'TeamB',
        'team1_score': 2, 'team2_score': 1, 'best_of': 3, 'is_lan': 1,
        'match_url': 'http://test', 'scraped_at': '2025-01-01T00:00:00Z',
        'source_url': 'http://test', 'parser_version': '0.1.0'
    })
    m = repo.get_match(1)
    assert m is not None
    assert m['team1_name'] == 'TeamA'
    assert repo.count_matches() == 1
    print('Repository OK')
    db.close()
"` from src/ directory.
  </verify>
  <done>
MatchRepository provides UPSERT for all 5 tables (individual and batch), plus basic read methods. All SQL uses ON CONFLICT DO UPDATE (not INSERT OR REPLACE). Transactions are atomic via `with conn:` blocks.
  </done>
</task>

<task type="auto">
  <name>Task 2: Comprehensive repository tests</name>
  <files>
    tests/test_repository.py
  </files>
  <action>
Create tests that exercise every repository method and verify UPSERT semantics, FK enforcement, and batch atomicity. Use a pytest fixture that creates a Database in tmp_path and initializes it, providing both db and repo fixtures.

**Fixtures:**

```python
@pytest.fixture
def db(tmp_path):
    database = Database(tmp_path / "test.db")
    database.initialize()
    yield database
    database.close()

@pytest.fixture
def repo(db):
    return MatchRepository(db.conn)
```

**Helper:** Create a `make_match_data(match_id=1, **overrides)` helper that returns a complete dict with all required fields and sensible defaults. Similarly `make_map_data(match_id=1, map_number=1, **overrides)`, `make_player_stats_data(match_id=1, map_number=1, player_id=1, **overrides)`, `make_round_data(match_id=1, map_number=1, round_number=1, **overrides)`, `make_economy_data(match_id=1, map_number=1, round_number=1, team_id=100, **overrides)`.

**Tests:**

UPSERT - Single row:
- `test_upsert_match_insert` -- Insert new match, get_match returns it
- `test_upsert_match_update` -- Upsert same match_id with different data, verify data is updated and only 1 row exists
- `test_upsert_match_updated_at` -- Upsert twice with different scraped_at, verify updated_at reflects second write
- `test_upsert_map_insert` -- Insert map (after inserting parent match), get_maps returns it
- `test_upsert_map_update` -- Upsert same (match_id, map_number) with changed map_name, verify updated
- `test_upsert_player_stats_insert` -- Insert player stats (after match + map), get_player_stats returns it
- `test_upsert_player_stats_update` -- Upsert with changed kills/deaths, verify updated
- `test_upsert_round_insert` -- Insert round (after match + map)
- `test_upsert_economy_insert` -- Insert economy row (after match + map + round)

UPSERT - Batch:
- `test_upsert_match_maps_atomic` -- upsert_match_maps inserts 1 match + 3 maps in one call
- `test_upsert_map_player_stats_batch` -- upsert_map_player_stats inserts 10 player rows (2 teams x 5 players)
- `test_upsert_map_rounds_batch` -- upsert_map_rounds inserts 24 rounds

Foreign key enforcement:
- `test_fk_map_without_match_raises` -- upsert_map for non-existent match_id raises IntegrityError
- `test_fk_player_stats_without_map_raises` -- upsert_player_stats for non-existent (match_id, map_number) raises IntegrityError
- `test_fk_round_without_map_raises` -- upsert_round for non-existent (match_id, map_number) raises IntegrityError
- `test_fk_economy_without_round_raises` -- upsert_economy for non-existent round raises IntegrityError

Read methods:
- `test_get_match_not_found` -- get_match for non-existent ID returns None
- `test_get_maps_empty` -- get_maps for match with no maps returns empty list
- `test_get_maps_ordered` -- Insert maps out of order, get_maps returns them ordered by map_number
- `test_count_matches_zero` -- count_matches on empty db returns 0
- `test_count_matches_after_inserts` -- Insert 3 matches, count returns 3

Nullable fields:
- `test_upsert_player_stats_nullable_ratings` -- rating_2 and rating_3 can both be None
- `test_upsert_player_stats_partial_performance` -- kpr, dpr, impact can be None (populated later in Phase 7)
  </action>
  <verify>
Run: `python -m pytest tests/test_repository.py -v` -- all tests pass.
Run: `python -m pytest tests/ -m "not integration" -v` -- full unit suite passes (Phase 1 + Phase 2, no regressions).
  </verify>
  <done>
All repository tests pass. UPSERT semantics verified: insert works, update-on-conflict works, only one row per key. FK enforcement verified. Batch operations are atomic. Read methods return correct results. Nullable fields handled. Full test suite (Phase 1 + 2) passes with no regressions.
  </done>
</task>

</tasks>

<verification>
1. `python -m pytest tests/test_repository.py -v` -- all tests pass
2. `python -m pytest tests/ -m "not integration" -v` -- complete unit suite passes
3. Upserting the same match twice produces exactly 1 row (verified by count_matches)
4. FK violations raise IntegrityError (maps without matches, player_stats without maps, etc.)
5. Batch operations are atomic (all-or-nothing within transaction)
</verification>

<success_criteria>
- MatchRepository provides UPSERT for all 5 tables using ON CONFLICT DO UPDATE
- Batch methods wrap multiple upserts in atomic transactions
- Read methods (get_match, get_maps, get_player_stats, count_matches) work correctly
- Foreign key enforcement prevents orphaned child rows
- All repository tests pass
- Full unit test suite (Phase 1 + Phase 2) passes with no regressions
</success_criteria>

<output>
After completion, create `.planning/phases/02-storage-foundation/02-02-SUMMARY.md`
</output>
