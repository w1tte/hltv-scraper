---
phase: 03-page-reconnaissance
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - data/recon/results-offset-0.html.gz
  - data/recon/results-offset-100.html.gz
  - data/recon/results-offset-5000.html.gz
  - data/recon/match-*.html.gz
  - data/recon/mapstats-*.html.gz
  - data/recon/performance-*.html.gz
  - data/recon/economy-*.html.gz
  - .planning/phases/03-page-reconnaissance/recon/sample-manifest.md
autonomous: true

must_haves:
  truths:
    - "Sample HTML exists on disk for all 5 page types: results listing, match overview, map stats, map performance, map economy"
    - "Samples span at least 3 distinct eras: late 2023, mid 2024, 2025-2026"
    - "At least one BO1, one BO3, one overtime match, and one forfeit/walkover match are included"
    - "A manifest file lists every sample with its characteristics"
  artifacts:
    - path: "data/recon/"
      provides: "All sample HTML files as .html.gz"
    - path: ".planning/phases/03-page-reconnaissance/recon/sample-manifest.md"
      provides: "Catalog of all fetched samples with match IDs, URLs, page types, eras, formats, edge case labels"
  key_links:
    - from: "fetch script"
      to: "src/scraper/http_client.py"
      via: "HLTVClient.fetch(url)"
      pattern: "async with HLTVClient"
---

<objective>
Fetch and archive representative sample HTML pages from HLTV covering all 5 page types the scraper will parse. Produce a manifest documenting every sample with its characteristics (era, format, tier, edge case type).

Purpose: All subsequent analysis plans (03-02 through 03-06) work against these saved HTML files offline, avoiding repeated live fetches that risk Cloudflare blocks.
Output: ~30-40 gzipped HTML files in `data/recon/` and a manifest file in the recon docs directory.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-page-reconnaissance/03-RESEARCH.md
@.planning/phases/03-page-reconnaissance/03-CONTEXT.md
@src/scraper/http_client.py
@src/scraper/storage.py
@src/scraper/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Write and execute sample fetching script</name>
  <files>data/recon/ (all .html.gz files)</files>
  <action>
Write a temporary Python script (`scripts/fetch_recon_samples.py`) that uses HLTVClient to fetch sample pages and save them as gzipped HTML to `data/recon/`.

**Install analysis dependencies first:**
```bash
pip install beautifulsoup4 lxml
```

**Sample selection - Claude must pick specific match URLs covering ALL of these criteria:**

1. **Results listing pages** (3 pages):
   - `https://www.hltv.org/results?offset=0` (most recent results)
   - `https://www.hltv.org/results?offset=100` (second page)
   - `https://www.hltv.org/results?offset=5000` (deep historical page, ~2024 era)

2. **Match overview pages** (6-8 matches spanning diversity):
   - One BO3 from a Major/tier-1 LAN, late 2023 (early CS2 era)
   - One BO1 from an online qualifier, mid 2024
   - One BO3 from a tier-1 LAN, late 2024 or early 2025
   - One BO3 from a recent 2025-2026 event
   - One BO5 (e.g., a Major grand final -- PGL Copenhagen 2024 or IEM Katowice 2025 or StarLadder Budapest 2025)
   - One overtime match (search results pages for matches where total rounds > 24)
   - One forfeit/walkover match (search HLTV for "forfeit" or "w/o" matches)
   - Optionally one showmatch if easily identifiable

3. **Map stats pages** (one mapstatsid per match selected above, ~6-8 pages):
   - For each match overview fetched, extract a mapstatsid link from the HTML
   - Fetch the map stats page for that mapstatsid
   - URL pattern: `https://www.hltv.org/stats/matches/mapstatsid/{id}/{slug}`

4. **Map performance pages** (same mapstatsids as above, ~6-8 pages):
   - URL pattern: `https://www.hltv.org/stats/matches/performance/mapstatsid/{id}/{slug}`

5. **Map economy pages** (same mapstatsids as above, ~6-8 pages):
   - URL pattern: `https://www.hltv.org/stats/matches/economy/mapstatsid/{id}/{slug}`

**Fetching strategy -- CRITICAL to avoid Cloudflare blocks:**
- Use the existing HLTVClient with default ScraperConfig (3-8s rate limiting built in)
- Fetch in 2-3 sessions of 10-15 pages each
- Between sessions, pause for 30-60 seconds
- Monitor `client.stats` for challenge count increasing -- if so, pause longer
- Log each fetch: URL, response size (chars), success/fail

**File naming convention:**
- Results: `data/recon/results-offset-{N}.html.gz`
- Match overview: `data/recon/match-{match_id}-overview.html.gz`
- Map stats: `data/recon/mapstats-{mapstatsid}-stats.html.gz`
- Map performance: `data/recon/performance-{mapstatsid}.html.gz`
- Map economy: `data/recon/economy-{mapstatsid}.html.gz`

**Saving method:**
- Results pages: simple gzip write (HtmlStorage does NOT support results pages)
  ```python
  import gzip
  from pathlib import Path
  Path("data/recon/results-offset-0.html.gz").write_bytes(
      gzip.compress(html.encode("utf-8"))
  )
  ```
- Match overview pages: simple gzip write to data/recon/ (use data/recon/ for all recon samples, not HtmlStorage)
- All map pages: simple gzip write to data/recon/

**IMPORTANT:**
- Do NOT use mapstatsid/178890 (known edge case, only 2295 chars, will fail the 10K threshold)
- If a fetch fails (Cloudflare challenge, timeout), log it and continue -- can retry later
- If a forfeit/walkover match is hard to find, try browsing results pages for entries with score "0 - 0" or "W/O" or look for matches where the overview page has no map stats links
- The fetch script is temporary tooling; it does not need tests or production-quality code
  </action>
  <verify>
Count files in data/recon/: should have 25-40 .html.gz files. Verify at least one file exists for each of the 5 page types (results, match overview, map stats, map performance, map economy). Verify no file is suspiciously small (< 10KB compressed = likely a Cloudflare page or error).

```bash
ls -la data/recon/*.html.gz | wc -l
ls -la data/recon/results-*.html.gz
ls -la data/recon/match-*.html.gz
ls -la data/recon/mapstats-*.html.gz
ls -la data/recon/performance-*.html.gz
ls -la data/recon/economy-*.html.gz
```
  </verify>
  <done>25+ gzipped HTML sample files exist in data/recon/ covering all 5 page types, multiple eras, and edge cases (BO1, BO3, BO5, overtime, forfeit)</done>
</task>

<task type="auto">
  <name>Task 2: Create sample manifest document</name>
  <files>.planning/phases/03-page-reconnaissance/recon/sample-manifest.md</files>
  <action>
After all samples are fetched, create a manifest file at `.planning/phases/03-page-reconnaissance/recon/sample-manifest.md` that catalogs every sample.

**Format:**

```markdown
# Sample Manifest

**Fetched:** {date}
**Total samples:** {count}
**Sessions:** {N} sessions, {total_time} approximate

## Results Listing Pages

| File | URL | Size (chars) | Notes |
|------|-----|-------------|-------|
| results-offset-0.html.gz | /results?offset=0 | ~250K | Most recent matches |
| ... | ... | ... | ... |

## Match Overview Pages

| File | Match ID | URL | Era | Format | Tier | Edge Case | Size (chars) |
|------|----------|-----|-----|--------|------|-----------|-------------|
| match-{id}-overview.html.gz | {id} | /matches/{id}/{slug} | 2023-Q4 | BO3 | Tier-1 LAN | - | ~180K |
| ... | ... | ... | ... | ... | ... | overtime | ~200K |

## Map Stats Pages

| File | MapStatsID | From Match | URL | Size (chars) |
|------|-----------|------------|-----|-------------|

## Map Performance Pages

| File | MapStatsID | From Match | URL | Size (chars) |
|------|-----------|------------|-----|-------------|

## Map Economy Pages

| File | MapStatsID | From Match | URL | Size (chars) |
|------|-----------|------------|-----|-------------|

## Coverage Matrix

| Criterion | Covered? | Sample(s) |
|-----------|----------|-----------|
| Late 2023 (early CS2) | Yes | match-{id} |
| Mid 2024 | Yes | match-{id} |
| 2025-2026 (recent) | Yes | match-{id} |
| BO1 | Yes | match-{id} |
| BO3 | Yes | match-{id}, match-{id} |
| BO5 | Yes | match-{id} |
| Overtime | Yes | match-{id} |
| Forfeit/walkover | Yes/No | match-{id} or "not found" |
| Tier-1 LAN | Yes | match-{id} |
| Tier-2/3 / Online | Yes | match-{id} |
```

**Populate the manifest using actual data** from the fetched files. Decompress each .html.gz to get the char count. Extract match details from the fetched overview HTML using BeautifulSoup (team names, event, date, format) to fill in the table.

**If any criterion was NOT covered** (e.g., could not find a forfeit match), document it clearly with a note explaining what was tried.
  </action>
  <verify>File exists at `.planning/phases/03-page-reconnaissance/recon/sample-manifest.md`. File contains tables for all 5 page types. Coverage matrix has entries for all criteria (era, format, tier, edge cases).</verify>
  <done>Manifest file exists, documents every fetched sample with metadata, and the coverage matrix confirms all target criteria are addressed (or explicitly notes gaps)</done>
</task>

</tasks>

<verification>
1. `data/recon/` contains 25+ .html.gz files
2. At least 3 results listing files, 6+ match overview files, 5+ each of map stats/performance/economy files
3. No .html.gz file is under 10KB compressed (would indicate Cloudflare page)
4. Manifest file exists and is populated with real data from fetched pages
5. Coverage matrix in manifest confirms era diversity, format diversity, and edge case coverage
</verification>

<success_criteria>
- All 5 HLTV page types have representative HTML samples saved to disk
- Samples span late 2023, mid 2024, and 2025-2026 eras
- BO1, BO3, BO5, and overtime are all represented
- Forfeit/walkover is either represented or explicitly documented as unfound
- Manifest catalogs every sample with enough metadata for downstream analysis plans to pick appropriate files
</success_criteria>

<output>
After completion, create `.planning/phases/03-page-reconnaissance/03-01-SUMMARY.md`
</output>
