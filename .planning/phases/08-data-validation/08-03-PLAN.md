---
phase: 08-data-validation
plan: 03
type: execute
wave: 3
depends_on: ["08-02"]
files_modified:
  - src/scraper/match_overview.py
  - src/scraper/map_stats.py
  - src/scraper/performance_economy.py
  - tests/test_match_overview.py
  - tests/test_map_stats.py
  - tests/test_performance_economy.py
autonomous: true

must_haves:
  truths:
    - "Every record passes through Pydantic validation before database insertion in all 3 orchestrators"
    - "Invalid records are quarantined and do not enter the main database tables"
    - "Validation failures do not halt the pipeline -- processing continues for remaining records"
    - "Batch-level checks (player count, economy alignment) run after individual validation and log warnings"
  artifacts:
    - path: "src/scraper/match_overview.py"
      provides: "Match overview orchestrator with validation"
      contains: "validate_and_quarantine"
    - path: "src/scraper/map_stats.py"
      provides: "Map stats orchestrator with validation"
      contains: "validate_batch"
    - path: "src/scraper/performance_economy.py"
      provides: "Performance+economy orchestrator with validation"
      contains: "validate_batch"
  key_links:
    - from: "src/scraper/match_overview.py"
      to: "src/scraper/validation.py"
      via: "import validate functions"
      pattern: "from scraper.validation import"
    - from: "src/scraper/match_overview.py"
      to: "src/scraper/models/__init__.py"
      via: "import model classes for validation routing"
      pattern: "from scraper.models import"
    - from: "src/scraper/map_stats.py"
      to: "src/scraper/validation.py"
      via: "validate_batch for player_stats and rounds"
      pattern: "from scraper.validation import"
    - from: "src/scraper/performance_economy.py"
      to: "src/scraper/validation.py"
      via: "validate_batch for perf stats, economy, kill matrix"
      pattern: "from scraper.validation import"
---

<objective>
Wire Pydantic validation into all 3 orchestrators (match_overview, map_stats, performance_economy) so every record is validated before database insertion. Update existing tests to cover validation integration.

Purpose: This is where validation becomes real -- not just models that could validate, but models that DO validate every record flowing into the database.
Output: All 3 orchestrators validate before persist, existing tests updated, invalid records quarantined.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-data-validation/08-CONTEXT.md
@.planning/phases/08-data-validation/08-RESEARCH.md
@.planning/phases/08-data-validation/08-01-SUMMARY.md
@.planning/phases/08-data-validation/08-02-SUMMARY.md
@src/scraper/match_overview.py
@src/scraper/map_stats.py
@src/scraper/performance_economy.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Wire validation into all 3 orchestrators</name>
  <files>
    src/scraper/match_overview.py
    src/scraper/map_stats.py
    src/scraper/performance_economy.py
  </files>
  <action>
    **match_overview.py** changes:

    Add imports: `from scraper.validation import validate_and_quarantine, validate_batch, check_player_count` and `from scraper.models import MatchModel, ForfeitMatchModel, MapModel, VetoModel, MatchPlayerModel`.

    In the parse+persist loop (after building match_data, maps_data, vetoes_data, players_data), insert validation BEFORE `match_repo.upsert_match_overview(...)`:

    1. Determine model class: use ForfeitMatchModel if any map has map_name "Default" (i.e., `any(m.is_forfeit_map for m in result.maps)` or check `result.is_forfeit` if the MatchOverview dataclass has it), else MatchModel.
    2. `validated_match = validate_and_quarantine(match_data, model_cls, {"match_id": match_id}, match_repo)`
    3. If validated_match is None: set stats["failed"] += 1, mark as failed, continue to next match.
    4. `validated_maps, maps_q = validate_batch(maps_data, MapModel, {"match_id": match_id}, match_repo)`
    5. `validated_vetoes, vetoes_q = validate_batch(vetoes_data, VetoModel, {"match_id": match_id}, match_repo)`
    6. `validated_players, players_q = validate_batch(players_data, MatchPlayerModel, {"match_id": match_id}, match_repo)`
    7. Run `check_player_count(validated_players, match_id, None)` -- log any warnings returned. This is warn-and-insert (do not reject on player count).
    8. Call `match_repo.upsert_match_overview(validated_match, validated_maps, validated_vetoes, validated_players)` with validated dicts.

    If any maps_q, vetoes_q, or players_q > 0, log a warning but do NOT skip the match -- partial data is better than no data. The quarantine already has the failed records.

    **map_stats.py** changes:

    Add imports: `from scraper.validation import validate_batch, check_player_count` and `from scraper.models import PlayerStatsModel, RoundHistoryModel`.

    In the parse+persist loop (after building stats_data and rounds_data), insert validation BEFORE `match_repo.upsert_map_stats_complete(...)`:

    1. `validated_stats, stats_q = validate_batch(stats_data, PlayerStatsModel, {"match_id": match_id, "map_number": map_number}, match_repo)`
    2. `validated_rounds, rounds_q = validate_batch(rounds_data, RoundHistoryModel, {"match_id": match_id, "map_number": map_number}, match_repo)`
    3. Run `check_player_count(validated_stats, match_id, map_number)` -- log warnings.
    4. If validated_stats is empty (all quarantined): log error, stats["failed"] += 1, continue.
    5. Call `match_repo.upsert_map_stats_complete(validated_stats, validated_rounds)` with validated data.

    **performance_economy.py** changes:

    Add imports: `from scraper.validation import validate_batch, check_economy_alignment` and `from scraper.models import PlayerStatsModel, EconomyModel, KillMatrixModel`.

    In the parse+persist loop (after building perf_stats, economy_data, kill_matrix_data), insert validation BEFORE `match_repo.upsert_perf_economy_complete(...)`:

    1. `validated_perf, perf_q = validate_batch(perf_stats, PlayerStatsModel, {"match_id": match_id, "map_number": map_number}, match_repo)`
    2. `validated_econ, econ_q = validate_batch(economy_data, EconomyModel, {"match_id": match_id, "map_number": map_number}, match_repo)`
    3. `validated_km, km_q = validate_batch(kill_matrix_data, KillMatrixModel, {"match_id": match_id, "map_number": map_number}, match_repo)`
    4. Run `check_economy_alignment(validated_econ, valid_rounds, match_id, map_number)` -- log warnings.
    5. If validated_perf is empty (all quarantined): log error, stats["failed"] += 1, continue.
    6. Call `match_repo.upsert_perf_economy_complete(validated_perf, validated_econ, validated_km)` with validated data.

    **CRITICAL -- do NOT change the function signatures** of run_match_overview, run_map_stats, or run_performance_economy. The validation is internal to each orchestrator.

    **CRITICAL -- never halt on validation failures**. Log, quarantine, continue. Per CONTEXT.md decisions.

    **NOTE on updated_at**: The validate_and_quarantine function (from Plan 02) auto-fills updated_at from scraped_at if missing. The orchestrators already include scraped_at in their dicts. This means the validated dicts will have updated_at set, which is fine -- the UPSERT SQL uses `excluded.scraped_at` for updated_at anyway, but having it in the dict satisfies the Pydantic model and the named parameter binding.
  </action>
  <verify>
    `python -c "from scraper.match_overview import run_match_overview; from scraper.map_stats import run_map_stats; from scraper.performance_economy import run_performance_economy; print('All orchestrators import cleanly')"` succeeds (no import errors from new validation imports).
  </verify>
  <done>All 3 orchestrators validate every record before database insertion, quarantine failures, log warnings, and never halt on validation errors.</done>
</task>

<task type="auto">
  <name>Task 2: Update existing orchestrator tests for validation</name>
  <files>
    tests/test_match_overview.py
    tests/test_map_stats.py
    tests/test_performance_economy.py
  </files>
  <action>
    The existing tests for orchestrators (test_match_overview.py, test_map_stats.py, test_performance_economy.py) mock out the repository and parser calls. With validation now running inside the orchestrators, the test data dicts must satisfy Pydantic validation or the tests will fail.

    Read each test file to understand the current mock data, then make targeted updates:

    1. **Ensure mock parser returns produce valid data**: The orchestrators build dicts from parser dataclass results. If the mock data has e.g. match_id=0 or missing scraped_at, validation will reject it. Fix any mock data that would fail Pydantic validation.

    2. **Add `insert_quarantine` to mocked repos**: The match_repo mock needs `insert_quarantine` as a no-op attribute (MagicMock auto-handles this, but verify).

    3. **Add quarantine-specific tests** (one per orchestrator test file):
       - test_match_overview_quarantines_invalid_match: Mock parser to return data that will fail MatchModel validation (e.g., team1_id=team2_id). Verify stats["failed"] increments and match is marked failed.
       - test_map_stats_quarantines_invalid_stats: Mock parser to return player with kills=-1. Verify the invalid player is quarantined but other valid players still persist.
       - test_perf_economy_quarantines_invalid_economy: Mock economy with buy_type="pistol" (invalid). Verify economy row is quarantined but perf stats and kill matrix still persist.

    4. **Verify existing tests still pass**: The validation should be transparent to happy-path tests because the mock data is valid. If any existing test breaks due to Pydantic rejecting mock data, fix the mock data (not the validation).

    **IMPORTANT**: Do NOT rewrite the test files from scratch. Read the existing tests first, understand the mock patterns, and make minimal additions/fixes.
  </action>
  <verify>
    `pytest tests/test_match_overview.py tests/test_map_stats.py tests/test_performance_economy.py -v` -- all tests pass (both existing and new).

    `pytest tests/ -m "not integration" -v` -- full unit test suite passes (no regressions).
  </verify>
  <done>All existing orchestrator tests pass with validation wired in. New quarantine tests verify that invalid records are rejected, quarantined, and do not halt the pipeline. Full unit test suite has zero regressions.</done>
</task>

</tasks>

<verification>
- `pytest tests/ -m "not integration"` -- full unit test suite passes with zero failures
- All 3 orchestrators import cleanly with validation imports
- Invalid data is quarantined (verified by quarantine-specific tests)
- Valid data flows through to upsert methods unchanged
- Pipeline never halts on validation failure (verified by test continuation behavior)
</verification>

<success_criteria>
- match_overview.py validates match, maps, vetoes, players before upsert
- map_stats.py validates player_stats and round_history before upsert
- performance_economy.py validates perf_stats, economy, kill_matrix before upsert
- Existing orchestrator tests pass without modification (or with minimal mock data fixes)
- New quarantine tests prove invalid records are caught and quarantined
- Full test suite (`pytest tests/ -m "not integration"`) passes with zero failures
</success_criteria>

<output>
After completion, create `.planning/phases/08-data-validation/08-03-SUMMARY.md`
</output>
