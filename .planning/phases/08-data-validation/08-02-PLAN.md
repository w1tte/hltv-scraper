---
phase: 08-data-validation
plan: 02
type: execute
wave: 2
depends_on: ["08-01"]
files_modified:
  - src/scraper/validation.py
  - tests/test_models.py
  - tests/test_validation.py
autonomous: true

must_haves:
  truths:
    - "A single validate_and_quarantine function validates a dict, returns validated dict on success or None on failure, and quarantines failures automatically"
    - "Batch-level checks enforce player count per map (10 players = 2 teams of 5) and economy-round alignment"
    - "Warnings for unusual-but-valid data are captured and logged, not suppressed"
    - "All model field constraints and cross-field validators are tested with both valid and invalid inputs"
  artifacts:
    - path: "src/scraper/validation.py"
      provides: "validate_and_quarantine, validate_batch, check_player_count, check_economy_alignment"
      exports: ["validate_and_quarantine", "validate_batch", "check_player_count", "check_economy_alignment"]
    - path: "tests/test_models.py"
      provides: "Unit tests for all 9 Pydantic models"
      min_lines: 150
    - path: "tests/test_validation.py"
      provides: "Unit tests for validation wrapper and batch checks"
      min_lines: 100
  key_links:
    - from: "src/scraper/validation.py"
      to: "src/scraper/models/__init__.py"
      via: "import models for model_validate"
      pattern: "from scraper.models import"
    - from: "src/scraper/validation.py"
      to: "src/scraper/repository.py"
      via: "repo.insert_quarantine for failed records"
      pattern: "insert_quarantine"
---

<objective>
Build the validation wrapper layer and comprehensive tests for all Pydantic models and validation logic.

Purpose: The validation wrapper is the bridge between parsers and persistence -- it decides what gets inserted and what gets quarantined. Tests prove the models actually catch the violations they claim to.
Output: validation.py with validate/quarantine functions, test_models.py, test_validation.py
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-data-validation/08-CONTEXT.md
@.planning/phases/08-data-validation/08-RESEARCH.md
@.planning/phases/08-data-validation/08-01-SUMMARY.md
@src/scraper/repository.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Validation wrapper module</name>
  <files>src/scraper/validation.py</files>
  <action>
    Create `src/scraper/validation.py` with these functions:

    **validate_and_quarantine(data, model_cls, context, repo) -> dict | None**
    - `data`: dict to validate
    - `model_cls`: Pydantic model class (e.g., MatchModel)
    - `context`: dict with match_id, map_number (for quarantine record and logging)
    - `repo`: MatchRepository (for quarantine insertion, can be None to skip quarantine)
    - Logic:
      1. Ensure `updated_at` key exists in data (set to `data.get("scraped_at", "")` if missing) -- the UPSERT SQL handles updated_at via excluded.scraped_at, but Pydantic models need the key
      2. Use `warnings.catch_warnings(record=True)` with `warnings.simplefilter("always")`
      3. Call `model_cls.model_validate(data)` inside the catch_warnings block
      4. Log any caught warnings via `logger.warning("Validation warning for %s (match %s, map %s): %s", model_cls.__name__, context.get("match_id"), context.get("map_number"), w.message)`
      5. Return `model.model_dump()` on success
      6. On ValidationError: log the error, build quarantine dict (entity_type=model_cls.__name__, match_id from context, map_number from context, raw_data=json.dumps(data, default=str), error_details=str(e), quarantined_at=now ISO, resolved=0), call repo.insert_quarantine if repo is not None, return None

    **validate_batch(items, model_cls, context, repo) -> tuple[list[dict], int]**
    - Validates a list of dicts, returns (valid_dicts, quarantine_count).
    - Calls validate_and_quarantine for each item. Collects valid results and counts quarantined.

    **check_player_count(stats_dicts, match_id, map_number) -> list[str]**
    - Takes list of validated player_stats dicts for one map.
    - Checks that len(stats_dicts) == 10 (2 teams of 5).
    - If not 10: returns list with warning string. Does NOT reject -- this is warn-and-insert per CONTEXT.md (Pitfall 5: coach stand-ins, subs).
    - If 10: returns empty list.

    **check_economy_alignment(economy_dicts, valid_round_numbers, match_id, map_number) -> list[str]**
    - Takes list of validated economy dicts and set of valid round numbers.
    - Checks every economy round_number is in valid_round_numbers (should already be filtered by orchestrator, but this is defense-in-depth).
    - Returns list of warning strings for any misaligned rounds (empty list = clean).

    Use `import logging; logger = logging.getLogger(__name__)` for all logging. Import json, warnings, datetime from stdlib.
  </action>
  <verify>
    `python -c "from scraper.validation import validate_and_quarantine, validate_batch, check_player_count, check_economy_alignment; print('All exports imported')"` succeeds.
  </verify>
  <done>validation.py provides validate_and_quarantine (single record), validate_batch (list), and two batch-level check functions.</done>
</task>

<task type="auto">
  <name>Task 2: Unit tests for models and validation</name>
  <files>
    tests/test_models.py
    tests/test_validation.py
  </files>
  <action>
    **tests/test_models.py** -- Test each Pydantic model class:

    For MatchModel:
    - test_valid_match: minimal valid dict passes
    - test_match_id_zero_rejected: match_id=0 raises ValidationError
    - test_same_team_ids_rejected: team1_id==team2_id raises ValidationError
    - test_score_exceeds_best_of_rejected: score 3-0 in BO3 raises (max is 2)
    - test_winner_low_score_warns: score 1-0 in BO3 triggers warning (not rejection)
    - test_forfeit_match_model_no_score_check: ForfeitMatchModel allows irregular scores

    For MapModel:
    - test_valid_map: minimal valid dict passes
    - test_half_scores_exceed_total_rejected: ct_rounds + t_rounds > total_rounds raises
    - test_overtime_half_scores_allowed: ct+t < total is fine (OT adds extra rounds)
    - test_extreme_ot_warns: total rounds > 50 triggers warning

    For PlayerStatsModel:
    - test_valid_player_stats: full valid dict passes
    - test_negative_kills_rejected: kills=-1 raises
    - test_kd_diff_mismatch_rejected: kills=20, deaths=10, kd_diff=5 raises (should be 10)
    - test_fk_diff_mismatch_rejected: opening_kills=5, opening_deaths=3, fk_diff=3 raises (should be 2)
    - test_hs_kills_exceed_kills_rejected: hs_kills=20, kills=15 raises
    - test_unusual_rating_warns: rating_3=4.5 triggers warning
    - test_unusual_adr_warns: adr=250.0 triggers warning
    - test_nulls_allowed_for_performance: kpr=None, dpr=None, impact=None all accepted

    For RoundHistoryModel:
    - test_valid_round: minimal valid dict passes
    - test_invalid_winner_side: winner_side="X" raises
    - test_invalid_win_type: win_type="surrender" raises

    For EconomyModel:
    - test_valid_economy: minimal valid dict passes
    - test_invalid_buy_type: buy_type="pistol" raises (canonical names are full_eco etc.)

    For VetoModel:
    - test_valid_veto: minimal valid dict passes
    - test_invalid_action: action="banned" raises (must be "removed")

    For MatchPlayerModel:
    - test_valid_match_player: passes
    - test_invalid_team_num: team_num=3 raises

    For KillMatrixModel:
    - test_valid_kill_matrix: passes
    - test_invalid_matrix_type: matrix_type="pistol" raises

    For all warning tests, use `warnings.catch_warnings(record=True)` to assert warnings are emitted.

    **tests/test_validation.py** -- Test the validation wrapper:

    - test_validate_and_quarantine_valid: returns validated dict, no quarantine
    - test_validate_and_quarantine_invalid: returns None, calls repo.insert_quarantine
    - test_validate_and_quarantine_no_repo: returns None on failure, does not crash when repo=None
    - test_validate_and_quarantine_adds_updated_at: data without updated_at gets it auto-filled
    - test_validate_batch_mixed: mix of valid and invalid items, returns correct counts
    - test_check_player_count_exactly_10: returns empty list
    - test_check_player_count_not_10: returns warning string
    - test_check_economy_alignment_clean: all rounds valid, empty list
    - test_check_economy_alignment_extra_round: round not in valid set returns warning

    Use pytest fixtures for common valid data dicts. Use `unittest.mock.MagicMock` for repo in validation tests (to verify insert_quarantine is called with correct args without needing a real DB).

    Both test files should use `pytest` style (functions, not classes). Import from `scraper.models` and `scraper.validation`.
  </action>
  <verify>
    `pytest tests/test_models.py tests/test_validation.py -v` -- all tests pass.

    Check that at least 20 tests exist: `pytest tests/test_models.py tests/test_validation.py --collect-only | tail -1` shows count.
  </verify>
  <done>Comprehensive test suite for all 9 Pydantic models (field constraints, cross-field validators, warnings) and validation wrapper (quarantine, batch, checks). All tests pass.</done>
</task>

</tasks>

<verification>
- `pytest tests/test_models.py tests/test_validation.py -v` -- all pass, 0 failures
- validation.py validate_and_quarantine correctly returns dict on success, None on failure
- Quarantine records contain entity_type, match_id, raw_data, error_details
- Batch-level checks (player count, economy alignment) return appropriate warnings
- Warning capture works: unusual values emit warnings that are logged
</verification>

<success_criteria>
- validate_and_quarantine handles both success and failure paths
- validate_batch processes lists and returns (valid, quarantine_count)
- check_player_count and check_economy_alignment enforce batch rules as warnings
- 20+ unit tests covering all model constraints, validators, and validation wrapper
- All tests pass with `pytest tests/test_models.py tests/test_validation.py -v`
</success_criteria>

<output>
After completion, create `.planning/phases/08-data-validation/08-02-SUMMARY.md`
</output>
