---
phase: 05-match-overview-extraction
plan: 03
type: execute
wave: 2
depends_on: ["05-01", "05-02"]
files_modified:
  - src/scraper/match_overview.py
  - src/scraper/config.py
  - tests/test_match_overview.py
autonomous: true

must_haves:
  truths:
    - "Orchestrator fetches match overview pages from HLTV, stores raw HTML, parses them, and persists all extracted data to the database"
    - "Orchestrator pulls pending matches from scrape_queue and updates their status to scraped or failed after processing"
    - "Orchestrator handles fetch failures by discarding the entire batch and keeping queue entries as pending"
    - "Orchestrator handles parse failures per-match by marking individual matches as failed and continuing"
    - "Orchestrator skips sub-page fetching (map stats, performance, economy) -- only overview pages"
  artifacts:
    - path: "src/scraper/match_overview.py"
      provides: "run_match_overview async orchestrator"
      exports: ["run_match_overview"]
      min_lines: 60
    - path: "tests/test_match_overview.py"
      provides: "Unit tests for orchestrator logic"
      min_lines: 50
  key_links:
    - from: "src/scraper/match_overview.py"
      to: "src/scraper/match_parser.py"
      via: "parse_match_overview function call"
      pattern: "parse_match_overview"
    - from: "src/scraper/match_overview.py"
      to: "src/scraper/repository.py"
      via: "upsert_match_overview method call"
      pattern: "upsert_match_overview"
    - from: "src/scraper/match_overview.py"
      to: "src/scraper/discovery_repository.py"
      via: "get_pending_matches and update_status calls"
      pattern: "get_pending_matches|update_status"
    - from: "src/scraper/match_overview.py"
      to: "src/scraper/storage.py"
      via: "save and load for overview HTML"
      pattern: "storage\\.save|storage\\.load"
---

<objective>
Create the async orchestrator that ties together fetching, storing, parsing, and persisting match overview data. This is the top-level entry point for Phase 5 execution.

Purpose: The parser (Plan 02) and repository (Plan 01) are isolated components. This orchestrator wires them together into the fetch-first batch flow described in CONTEXT.md: fetch N pages, store raw HTML, then parse the batch and persist to DB.

Output: `src/scraper/match_overview.py` with `run_match_overview()` function. `tests/test_match_overview.py` with unit tests for orchestrator logic. Updated `src/scraper/config.py` with batch_size config.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-match-overview-extraction/05-RESEARCH.md
@.planning/phases/05-match-overview-extraction/05-01-SUMMARY.md
@.planning/phases/05-match-overview-extraction/05-02-SUMMARY.md

@src/scraper/discovery.py
@src/scraper/match_parser.py
@src/scraper/repository.py
@src/scraper/discovery_repository.py
@src/scraper/storage.py
@src/scraper/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add batch_size config and create orchestrator</name>
  <files>
    src/scraper/config.py
    src/scraper/match_overview.py
  </files>
  <action>
**config.py update:**

Add one field to ScraperConfig dataclass:
```python
# Match overview batch size
overview_batch_size: int = 10  # Matches to fetch per batch before parsing
```

**Create `src/scraper/match_overview.py`:**

Follow the exact pattern from `run_discovery` in `discovery.py`: async function, untyped parameters to avoid circular imports, logging, stats dict return.

```python
"""Match overview extraction orchestrator.

Coordinates fetching, storing, parsing, and persisting match overview data.
Pulls pending matches from the scrape_queue, fetches their overview pages,
stores raw HTML, parses with parse_match_overview(), and persists all
extracted data (match, maps, vetoes, players) to the database.
"""

import logging
from datetime import datetime, timezone

from scraper.match_parser import parse_match_overview

logger = logging.getLogger(__name__)

PARSER_VERSION = "match_overview_v1"


async def run_match_overview(
    client,              # HLTVClient
    match_repo,          # MatchRepository
    discovery_repo,      # DiscoveryRepository
    storage,             # HtmlStorage
    config,              # ScraperConfig
) -> dict:
```

**Orchestrator logic:**

1. Call `discovery_repo.get_pending_matches(limit=config.overview_batch_size)` to get the batch.

2. If no pending matches, log info and return early with stats showing 0 work.

3. **Fetch phase** -- For each queue entry in the batch:
   - Build URL: `config.base_url + entry['url']`
   - Fetch via `await client.fetch(url)`
   - Save raw HTML via `storage.save(html, match_id=entry['match_id'], page_type="overview")`
   - Track fetched match_ids in a list
   - **On ANY fetch failure**: Log the error. Discard the ENTIRE batch (per CONTEXT.md: "On fetch failure mid-batch: discard the entire partial batch"). Return stats with `fetch_errors` count. Do NOT update any queue statuses -- they remain 'pending' for retry.

4. **Parse + persist phase** -- For each successfully fetched match_id:
   - Load HTML from storage: `storage.load(match_id=match_id, page_type="overview")`
   - Parse: `result = parse_match_overview(html, match_id)`
   - Build provenance dict: `now = datetime.now(timezone.utc).isoformat()`, `source_url = config.base_url + entry['url']`
   - Convert MatchOverview to dicts for repository:
     - `match_data`: dict with keys matching UPSERT_MATCH parameters (match_id, date from date_unix_ms converted to ISO 8601, event_id, event_name, team1_id, team1_name, team2_id, team2_name, team1_score, team2_score, best_of, is_lan, match_url, scraped_at, source_url, parser_version)
     - `maps_data`: list of dicts, one per MapResult (match_id, map_number, mapstatsid, map_name, team1_rounds, team2_rounds, team1_ct_rounds, team1_t_rounds, team2_ct_rounds, team2_t_rounds, scraped_at, source_url, parser_version)
     - `vetoes_data`: list of dicts from VetoStep (match_id, step_number, team_name, action, map_name, scraped_at, source_url, parser_version). Empty list if vetoes is None.
     - `players_data`: list of dicts from PlayerEntry (match_id, player_id, player_name, team_id, team_num, scraped_at, source_url, parser_version)
   - Call `match_repo.upsert_match_overview(match_data, maps_data, vetoes_data, players_data)`
   - Call `discovery_repo.update_status(match_id, 'scraped')`
   - **On parse/persist failure for a single match**: Log the error with match_id. Call `discovery_repo.update_status(match_id, 'failed')`. Continue to next match (do NOT abort the batch).

5. Return stats dict: `{"batch_size": N, "fetched": N, "parsed": N, "failed": N, "fetch_errors": 0}`.

**Date conversion:** Convert `date_unix_ms` (int, milliseconds) to ISO 8601 string for the `matches.date` column:
```python
from datetime import datetime, timezone
date_iso = datetime.fromtimestamp(date_unix_ms / 1000, tz=timezone.utc).strftime("%Y-%m-%d")
```

**Match URL:** Store as `entry['url']` (relative URL from scrape_queue, e.g., `/matches/2389951/...`).
  </action>
  <verify>
Run `python -c "from scraper.match_overview import run_match_overview; print('OK')"` -- must print OK.
  </verify>
  <done>match_overview.py exports run_match_overview. Config has overview_batch_size field. Orchestrator implements fetch-first batching with batch-level fetch failure handling and per-match parse failure handling.</done>
</task>

<task type="auto">
  <name>Task 2: Create orchestrator unit tests</name>
  <files>tests/test_match_overview.py</files>
  <action>
Create `tests/test_match_overview.py` testing the orchestrator logic. Since the orchestrator is async and depends on HLTVClient (which needs Chrome), tests should mock external dependencies.

**Test approach:** Test the data conversion and persistence wiring by mocking the client.fetch call to return real HTML from recon samples, and using real in-memory database instances for repo/storage. This tests the full parse-to-persist path without needing Chrome.

**Setup:**
```python
import gzip
import asyncio
from pathlib import Path
from unittest.mock import AsyncMock, MagicMock
import pytest
from scraper.config import ScraperConfig
from scraper.db import Database
from scraper.repository import MatchRepository
from scraper.discovery_repository import DiscoveryRepository
from scraper.storage import HtmlStorage
from scraper.match_overview import run_match_overview

RECON_DIR = Path(__file__).resolve().parent.parent / "data" / "recon"

def load_sample(filename: str) -> str:
    path = RECON_DIR / filename
    if not path.exists():
        pytest.skip(f"Sample not found: {path}")
    return gzip.decompress(path.read_bytes()).decode("utf-8")
```

**Fixtures:**
- `db` fixture: Database at tmp_path, initialized with migrations
- `match_repo` fixture: MatchRepository(db.conn)
- `discovery_repo` fixture: DiscoveryRepository(db.conn)
- `storage` fixture: HtmlStorage(tmp_path / "raw")
- `config` fixture: ScraperConfig(data_dir=str(tmp_path), overview_batch_size=2)
- `mock_client` fixture: MagicMock with `fetch = AsyncMock()` that returns real HTML from a recon sample

**Seed helper:** Insert a pending entry into scrape_queue for a known match_id with real URL.

**Test class TestRunMatchOverview:**

- `test_fetches_parses_persists_match`: Seed one pending match (2389951). Mock client.fetch to return the corresponding HTML. Run orchestrator. Assert: match exists in matches table, maps exist, vetoes exist, players exist, scrape_queue status is 'scraped'.

- `test_no_pending_matches_returns_early`: Don't seed any pending matches. Run orchestrator. Assert stats show 0 work, client.fetch never called.

- `test_fetch_failure_discards_batch`: Seed 2 pending matches. Mock client.fetch to succeed on first, raise Exception on second. Run orchestrator. Assert: both queue entries remain 'pending' (batch discarded). No data in matches table.

- `test_parse_failure_marks_individual_failed`: Seed 2 pending matches. Mock client.fetch to return valid HTML for first, return garbage HTML (that will cause parser to fail) for second. Run orchestrator. Assert: first match parsed and persisted (status 'scraped'), second match status 'failed'.

- `test_forfeit_match_persisted_correctly`: Seed one pending forfeit match (2380434). Mock client.fetch to return forfeit HTML. Run orchestrator. Assert: match exists in DB, maps include a forfeit map, no mapstatsids, status is 'scraped'.

- `test_stats_dict_returned`: Seed 2 pending matches. Mock successful fetch/parse. Assert returned dict has keys batch_size, fetched, parsed, failed.

- `test_date_converted_to_iso`: Seed and process one match. Read match from DB. Assert date column is ISO 8601 format string (YYYY-MM-DD).

All async tests must use `@pytest.mark.asyncio` decorator (project uses pytest-asyncio strict mode).
  </action>
  <verify>
Run `pytest tests/test_match_overview.py -v` -- all tests must pass.
  </verify>
  <done>All orchestrator tests pass. Tests verify the full fetch-store-parse-persist pipeline using mocked client with real HTML samples and real in-memory database. Batch failure handling and per-match failure handling both verified.</done>
</task>

</tasks>

<verification>
1. `pytest tests/test_match_overview.py -v` -- all tests pass
2. `pytest tests/ -m "not integration" -v` -- all unit tests pass (no regressions)
3. `python -c "from scraper.match_overview import run_match_overview; print('OK')"` -- imports cleanly
4. Config.overview_batch_size defaults to 10
</verification>

<success_criteria>
- run_match_overview orchestrates the complete fetch-store-parse-persist pipeline
- Fetch failures discard entire batch (queue entries remain pending)
- Parse failures mark individual matches as failed (other matches in batch continue)
- Dates are converted from unix ms to ISO 8601 for DB storage
- Stats dict returned with batch_size, fetched, parsed, failed counts
- All unit tests pass with mocked client and real database
- No regressions in existing test suite
</success_criteria>

<output>
After completion, create `.planning/phases/05-match-overview-extraction/05-03-SUMMARY.md`
</output>
