---
phase: 07-performance-and-economy-extraction
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - src/scraper/economy_parser.py
  - tests/test_economy_parser.py
autonomous: true

must_haves:
  truths:
    - "Parser extracts per-round equipment values for both teams from FusionCharts JSON"
    - "Parser classifies buy types using HLTV thresholds: full_eco <$5K, semi_eco $5K-$10K, semi_buy $10K-$20K, full_buy $20K+"
    - "Parser extracts round win/loss and CT/T side from anchorImageUrl in FusionChart data points"
    - "Parser handles OT correctly: MR15 matches have all rounds, MR12 OT matches have regulation rounds only (24 max)"
    - "All 12 recon samples parse without errors"
  artifacts:
    - path: "src/scraper/economy_parser.py"
      provides: "Pure function economy page parser"
      exports: ["parse_economy", "EconomyData", "RoundEconomy"]
      min_lines: 80
    - path: "tests/test_economy_parser.py"
      provides: "Parser tests against 12 real HTML samples"
      min_lines: 120
  key_links:
    - from: "src/scraper/economy_parser.py"
      to: "data/recon/economy-*.html.gz"
      via: "Parser logic derived from FusionChart JSON structure in recon samples"
      pattern: "data-fusionchart-config"
    - from: "src/scraper/economy_parser.py"
      to: "json.loads"
      via: "FusionChart JSON extraction for equipment values"
      pattern: "categories.*category.*label"
---

<objective>
Build a pure-function parser that extracts per-round economy data from HLTV economy pages.

Purpose: The economy page contains per-round equipment values for both teams embedded in FusionChart JSON, plus round win/loss and side (CT/T) indicators. This data fills the economy table with equipment_value and buy_type per round per team. The parser must handle OT discrepancies between MR15 (all rounds) and MR12 (regulation only, 24 max).

NOTE on buy type categories: The original schema comment in migrations/001_initial_schema.sql says `buy_type TEXT -- "eco", "force", "full", "pistol"`. Phase 7 uses different, more precise categories derived from HLTV's own threshold lines: `full_eco`, `semi_eco`, `semi_buy`, `full_buy`. These are the canonical category names going forward. The original schema comment was a placeholder written before Phase 3 recon discovered the actual HLTV thresholds.

Output: `src/scraper/economy_parser.py` (pure function) + comprehensive test suite against all 12 recon samples.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-performance-and-economy-extraction/07-RESEARCH.md
@.planning/phases/03-page-reconnaissance/recon/map-economy.md

# Pattern reference
@src/scraper/map_stats_parser.py
@tests/test_map_stats_parser.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Economy page parser implementation</name>
  <files>src/scraper/economy_parser.py</files>
  <action>
Create `src/scraper/economy_parser.py` following the established pure-function parser pattern.

**Dataclasses:**

```python
@dataclass
class RoundEconomy:
    round_number: int
    team_name: str
    equipment_value: int
    buy_type: str          # "full_eco", "semi_eco", "semi_buy", "full_buy"
    won_round: bool
    side: str | None       # "CT" or "T" (from anchor image); None if not determinable

@dataclass
class EconomyData:
    mapstatsid: int
    team1_name: str
    team2_name: str
    rounds: list[RoundEconomy]
    round_count: int       # Number of rounds with economy data (may be < total score for MR12 OT)
```

**Buy type categories (canonical for this project):**
- `full_eco`: equipment_value < $5,000
- `semi_eco`: $5,000 <= equipment_value < $10,000
- `semi_buy`: $10,000 <= equipment_value < $20,000
- `full_buy`: equipment_value >= $20,000

These categories replace the placeholder names ("eco", "force", "full", "pistol") from the original schema comment. They are derived from HLTV's own threshold trendlines documented in Phase 3 recon.

**Main function:**
```python
def parse_economy(html: str, mapstatsid: int) -> EconomyData:
```

**Implementation details:**

1. `_parse_fusionchart_economy(soup)`: Select `worker-ignore.graph[data-fusionchart-config]`. Parse JSON. Extract:
   - `ds = config['dataSource']`
   - `round_labels = [cat['label'] for cat in ds['categories'][0]['category']]` -- these are round numbers as strings ("1", "2", ...)
   - `ds['dataset']` has 2 entries (one per team). Each has `seriesname` (team name) and `data` (array of per-round data points).
   - For each dataset/team, iterate over `data` array alongside round_labels:
     - `round_number = int(round_labels[i])`
     - `equipment_value = int(point['value'])` -- NOTE: for economy page, `value` IS the actual equipment value (unlike performance page where `value` is normalized). The economy chart has no `displayValue` key.
     - `won_round`: determined by presence of `anchorImageUrl` -- if present, team won this round; if absent/None, team lost
     - `side`: if `anchorImageUrl` contains "ctRoundWon" -> "CT"; if "tRoundWon" -> "T"; otherwise None. If no anchorImageUrl, try to infer from opponent's anchor (opponent's CT win = this team was T side).

2. `_classify_buy_type(value: int) -> str`:
   - `value >= 20000` -> "full_buy"
   - `value >= 10000` -> "semi_buy"
   - `value >= 5000` -> "semi_eco"
   - `value < 5000` -> "full_eco"
   These thresholds match the HLTV trendlines documented in Phase 3 recon.

3. Side inference logic: For each round, exactly one team has an anchorImageUrl (the winner). The winner's anchor tells us the winner's side. The loser's side is the opposite. Build a `round_sides: dict[int, dict[str, str]]` mapping where for each round we store both teams' sides:
   - Winner has "ctRoundWon" -> winner was CT, loser was T
   - Winner has "tRoundWon" -> winner was T, loser was CT
   Then assign sides to each RoundEconomy entry accordingly.

4. Handle edge cases:
   - OT: The FusionChart may have fewer rounds than the total score implies for MR12 matches. Simply extract whatever rounds are in the data. Set `round_count` to `len(round_labels)`.
   - Missing anchorImageUrl for all points in a round: both sides None, won_round False for both teams. This shouldn't happen but be defensive.

**Error handling:** Raise `ValueError` if no FusionChart element found. Use `logger.warning()` for minor issues (missing anchor images, unexpected round count).

**Imports:** `json`, `logging`, `dataclasses.dataclass`, `bs4.BeautifulSoup`.
  </action>
  <verify>
`python -c "from scraper.economy_parser import parse_economy, EconomyData, RoundEconomy; print('Imports OK')"` succeeds.
  </verify>
  <done>Economy parser module exists with parse_economy() pure function, dataclasses, buy type classifier, and FusionChart extraction with side inference logic.</done>
</task>

<task type="auto">
  <name>Task 2: Economy parser test suite</name>
  <files>tests/test_economy_parser.py</files>
  <action>
Create `tests/test_economy_parser.py` following the pattern from `tests/test_map_stats_parser.py`.

**Test infrastructure:**
```python
RECON_DIR = Path(__file__).resolve().parent.parent / "data" / "recon"
ALL_SAMPLES = [
    ("economy-162345.html.gz", 162345),   # MR15 or MR12 with OT
    ("economy-164779.html.gz", 164779),
    ("economy-164780.html.gz", 164780),
    ("economy-173424.html.gz", 173424),
    ("economy-174112.html.gz", 174112),
    ("economy-174116.html.gz", 174116),
    ("economy-179210.html.gz", 179210),
    ("economy-188093.html.gz", 188093),
    ("economy-206389.html.gz", 206389),   # MR12 OT (regulation only in data)
    ("economy-206393.html.gz", 206393),
    ("economy-219128.html.gz", 219128),
    ("economy-219151.html.gz", 219151),
]
```

**Test classes:**

1. `TestPerRoundExtraction` (fixture: sample 164779):
   - `test_rounds_extracted` -- `len(result.rounds) > 0`
   - `test_two_entries_per_round` -- each round_number appears exactly twice (once per team)
   - `test_equipment_values_positive` -- all equipment_value > 0
   - `test_round_numbers_sequential` -- round numbers are contiguous from 1 to round_count
   - `test_team_names_match` -- result.team1_name and team2_name are both non-empty strings

2. `TestBuyTypeClassification`:
   - `test_full_eco_boundary` -- `_classify_buy_type(4999)` == "full_eco"
   - `test_semi_eco_boundary` -- `_classify_buy_type(5000)` == "semi_eco"
   - `test_semi_buy_boundary` -- `_classify_buy_type(10000)` == "semi_buy"
   - `test_full_buy_boundary` -- `_classify_buy_type(20000)` == "full_buy"
   - `test_zero_value` -- `_classify_buy_type(0)` == "full_eco"
   - `test_high_value` -- `_classify_buy_type(50000)` == "full_buy"
   NOTE: Import `_classify_buy_type` directly for unit testing. If it's private, test through the round data instead (check buy_type values against known equipment values).

3. `TestRoundOutcomes` (fixture: sample 164779):
   - `test_exactly_one_winner_per_round` -- for each round_number, exactly one team has won_round=True and one has won_round=False
   - `test_sides_present` -- most rounds have non-None side values
   - `test_sides_opposite` -- when both sides are known for a round, they are CT/T opposites
   - `test_ct_t_only` -- all non-None sides are either "CT" or "T"

4. `TestOvertimeHandling`:
   - Use sample 162345 (known to have OT, MR15 era -- should have >24 rounds in data)
   - Use sample 206389 (MR12 OT -- should have exactly 24 rounds in data, regulation only)
   - `test_mr15_ot_all_rounds` -- sample 162345: round_count matches total rounds in the data (>24 expected)
   - `test_mr12_ot_regulation_only` -- sample 206389: round_count <= 24 (regulation rounds only)
   - `test_round_count_matches_data` -- `result.round_count == len(set(r.round_number for r in result.rounds))`

5. `TestTeamAttribution` (fixture: sample 164779):
   - `test_two_team_names` -- result.team1_name != result.team2_name
   - `test_teams_in_rounds` -- every round entry has team_name matching either team1_name or team2_name

6. `TestAllSamplesParseWithoutCrash` -- parametrize across ALL_SAMPLES:
   - `test_parse_succeeds` -- `parse_economy(html, msid)` returns EconomyData without exception
   - `test_has_rounds` -- `len(result.rounds) > 0`
   - `test_round_count_positive` -- `result.round_count > 0`
   - `test_buy_types_valid` -- all buy_type values are in {"full_eco", "semi_eco", "semi_buy", "full_buy"}
  </action>
  <verify>
`pytest tests/test_economy_parser.py -v --tb=short` -- all tests pass.
  </verify>
  <done>Test suite covers per-round extraction, buy type classification boundaries, round outcomes, OT handling (MR15 vs MR12), team attribution, and smoke tests across all 12 samples. All tests pass.</done>
</task>

</tasks>

<verification>
1. `pytest tests/test_economy_parser.py -v --tb=short` -- all tests pass
2. `python -c "import gzip; from pathlib import Path; from scraper.economy_parser import parse_economy; html = gzip.decompress(Path('data/recon/economy-164779.html.gz').read_bytes()).decode(); r = parse_economy(html, 164779); print(f'Rounds: {r.round_count}, Entries: {len(r.rounds)}, Team1: {r.team1_name}, Team2: {r.team2_name}')"` -- outputs expected data
3. `python -c "import gzip; from pathlib import Path; from scraper.economy_parser import parse_economy; html = gzip.decompress(Path('data/recon/economy-206389.html.gz').read_bytes()).decode(); r = parse_economy(html, 206389); print(f'MR12 OT test - Rounds: {r.round_count}')"` -- round_count should be <= 24
</verification>

<success_criteria>
- parse_economy() extracts per-round equipment values for both teams
- Buy types correctly classified using canonical names: full_eco, semi_eco, semi_buy, full_buy (replacing original placeholder names eco/force/full/pistol)
- Round win/loss correctly determined from anchorImageUrl presence
- CT/T side correctly inferred from anchor image filename
- MR12 OT matches return only regulation rounds (24 max)
- MR15 OT matches return all available rounds
- All 12 recon samples parse without errors
</success_criteria>

<output>
After completion, create `.planning/phases/07-performance-and-economy-extraction/07-03-SUMMARY.md`
</output>
